{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_dir = './images/'\n",
    "\n",
    "# Получение путей файлов и меток\n",
    "file_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if fname.endswith('.jpg')]\n",
    "labels = [fname.split('_')[0] for fname in os.listdir(data_dir) if fname.endswith('.jpg')]\n",
    "\n",
    "# Конвертируем метки в числовой формат\n",
    "label_to_id = {label: idx for idx, label in enumerate(set(labels))}\n",
    "ids = [label_to_id[label] for label in labels]\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(file_paths, ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем DataFrame для удобства работы с ImageDataGenerator\n",
    "train_df = pd.DataFrame({\n",
    "    'filename': X_train,\n",
    "    'class': [label for id in y_train for label, idx in label_to_id.items() if idx == id]\n",
    "})\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': X_test,\n",
    "    'class': [label for id in y_test for label, idx in label_to_id.items() if idx == id]\n",
    "})\n",
    "\n",
    "# Настройка генераторов данных\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='input',\n",
    "    drop_remainder=True  # Обеспечивает, что все батчи будут иметь размер 32\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filename',\n",
    "    y_col='class',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='input'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, Conv2DTranspose, LeakyReLU, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "def build_generator(z_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=(z_dim,)))\n",
    "\n",
    "    # Инициируем размер как 8x8\n",
    "    model.add(Dense(256 * 8 * 8, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(Reshape((8, 8, 256)))\n",
    "\n",
    "    # Первый увеличивающий слой до 16x16\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(negative_slope=0.01))\n",
    "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "\n",
    "    # Второй увеличивающий слой до 32x32\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(negative_slope=0.01))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "\n",
    "    # Третий увеличивающий слой до 64x64\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(negative_slope=0.01))\n",
    "    model.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "\n",
    "    # Выходной слой с размером изображения 64x64 и трех цветовыми каналами\n",
    "    model.add(Conv2DTranspose(3, kernel_size=4, strides=1, padding='same', activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "z_dim = 100\n",
    "generator = build_generator(z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Conv2D, Dropout, LeakyReLU, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Входной слой\n",
    "    model.add(Input(shape=img_shape))\n",
    "\n",
    "    # Первый сверточный слой\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding='same', \n",
    "                     kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(negative_slope=0.01))  # Замена alpha на negative_slope\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Второй сверточный слой\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', \n",
    "                     kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(negative_slope=0.01))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Третий сверточный слой\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same', \n",
    "                     kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(negative_slope=0.01))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # Выходной слой\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "img_shape = (64, 64, 3)\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.0002), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False  # Замораживаем дискриминатор при обучении GAN\n",
    "\n",
    "    # Входной слой для генератора (шумовой вектор z)\n",
    "    z = Input(shape=(z_dim,))\n",
    "\n",
    "    # Генерация изображения генератором\n",
    "    img = generator(z)\n",
    "\n",
    "    # Оценка дискриминатором сгенерированного изображения\n",
    "    valid = discriminator(img)\n",
    "\n",
    "    # Сборка модели GAN\n",
    "    gan_model = Model(inputs=z, outputs=valid)\n",
    "    gan_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "    return gan_model\n",
    "\n",
    "gan = build_gan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_gan(gan, generator, discriminator, train_generator, z_dim, epochs=1000, batch_size=128, sample_interval=100):\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, _ in train_generator:\n",
    "            current_batch_size = imgs.shape[0]  # Получаем размер текущего батча\n",
    "            \n",
    "            if current_batch_size != batch_size:\n",
    "                continue  # Пропускаем батч, если его размер не соответствует ожидаемому\n",
    "\n",
    "            real = np.ones((current_batch_size, 1))\n",
    "            fake = np.zeros((current_batch_size, 1))\n",
    "\n",
    "            z = np.random.normal(0, 1, (current_batch_size, z_dim))\n",
    "            gen_imgs = generator.predict(z)\n",
    "\n",
    "            discriminator.trainable = True\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, real)\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            discriminator.trainable = False\n",
    "            z = np.random.normal(0, 1, (current_batch_size, z_dim))\n",
    "            g_loss = gan.train_on_batch(z, real)\n",
    "\n",
    "            if (epoch + 1) % sample_interval == 0:\n",
    "                print(f\"Epoch {epoch + 1}: D loss: {d_loss[0]:.4f}, acc.: {100*d_loss[1]:.2f}% G loss: {g_loss:.4f}\")\n",
    "                sample_images(generator, z_dim, epoch)\n",
    "\n",
    "            if current_batch_size < batch_size:\n",
    "                break  # Выходим из цикла, если последний батч меньше ожидаемого\n",
    "\n",
    "def sample_images(generator, z_dim, epoch, image_grid_rows=4, image_grid_columns=4):\n",
    "    # Семплируем случайный шум\n",
    "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
    "\n",
    "    # Генерируем изображения из шума\n",
    "    gen_imgs = generator.predict(z)\n",
    "\n",
    "    # Масштабируем изображения к диапазону [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    # Устанавливаем размеры сетки изображений\n",
    "    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(4, 4), sharey=True, sharex=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for i in range(image_grid_rows):\n",
    "        for j in range(image_grid_columns):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, :], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"/kaggle/working/epoch_%d.png\" % epoch)\n",
    "    plt.close()\n",
    "\n",
    "z_dim = 100\n",
    "epochs = 10000\n",
    "batch_size = 32\n",
    "sample_interval = 1000\n",
    "\n",
    "train_gan(gan, generator, discriminator, train_generator, z_dim, epochs, batch_size, sample_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
